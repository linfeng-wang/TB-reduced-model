digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140668769614400 [label="
 (2, 13)" fillcolor=darkolivegreen1]
	140668773022736 [label=AddmmBackward0]
	140668773020768 -> 140668773022736
	140668432932752 [label="prediction_layer.bias
 (13)" fillcolor=lightblue]
	140668432932752 -> 140668773020768
	140668773020768 [label=AccumulateGrad]
	140668773022112 -> 140668773022736
	140668773022112 [label=ReluBackward0]
	140668773021248 -> 140668773022112
	140668773021248 [label=NativeBatchNormBackward0]
	140668773023120 -> 140668773021248
	140668773023120 [label=AddmmBackward0]
	140668773021104 -> 140668773023120
	140668972035424 [label="dense_layers.0.1.bias
 (64)" fillcolor=lightblue]
	140668972035424 -> 140668773021104
	140668773021104 [label=AccumulateGrad]
	140668773023024 -> 140668773023120
	140668773023024 [label=NativeDropoutBackward0]
	140668773022544 -> 140668773023024
	140668773022544 [label=MaxBackward0]
	140668773023504 -> 140668773022544
	140668773023504 [label=ReluBackward0]
	140668773022880 -> 140668773023504
	140668773022880 [label=CudnnBatchNormBackward0]
	140668773023072 -> 140668773022880
	140668773023072 [label=ConvolutionBackward0]
	140668773022784 -> 140668773023072
	140668972032784 [label="feature_extraction_layer.1.weight
 (128, 4, 25)" fillcolor=lightblue]
	140668972032784 -> 140668773022784
	140668773022784 [label=AccumulateGrad]
	140668771614048 -> 140668773023072
	140668972032704 [label="feature_extraction_layer.1.bias
 (128)" fillcolor=lightblue]
	140668972032704 -> 140668771614048
	140668771614048 [label=AccumulateGrad]
	140668773022400 -> 140668773022880
	140668972010288 [label="feature_extraction_layer.2.weight
 (128)" fillcolor=lightblue]
	140668972010288 -> 140668773022400
	140668773022400 [label=AccumulateGrad]
	140668773021296 -> 140668773022880
	140668972032224 [label="feature_extraction_layer.2.bias
 (128)" fillcolor=lightblue]
	140668972032224 -> 140668773021296
	140668773021296 [label=AccumulateGrad]
	140668773023456 -> 140668773023120
	140668773023456 [label=TBackward0]
	140668773021632 -> 140668773023456
	140668972035584 [label="dense_layers.0.1.weight
 (64, 128)" fillcolor=lightblue]
	140668972035584 -> 140668773021632
	140668773021632 [label=AccumulateGrad]
	140668773020576 -> 140668773021248
	140668972035904 [label="dense_layers.0.2.weight
 (64)" fillcolor=lightblue]
	140668972035904 -> 140668773020576
	140668773020576 [label=AccumulateGrad]
	140668773023360 -> 140668773021248
	140668972035664 [label="dense_layers.0.2.bias
 (64)" fillcolor=lightblue]
	140668972035664 -> 140668773023360
	140668773023360 [label=AccumulateGrad]
	140668773022928 -> 140668773022736
	140668773022928 [label=TBackward0]
	140668773021152 -> 140668773022928
	140668432932512 [label="prediction_layer.weight
 (13, 64)" fillcolor=lightblue]
	140668432932512 -> 140668773021152
	140668773021152 [label=AccumulateGrad]
	140668773022736 -> 140668769614400
}
